{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89140852-ab02-41b0-aa97-f41ace7e8db2",
   "metadata": {},
   "source": [
    "# Etapas Básicas de um Projeto de Machine Learning\n",
    "\n",
    "Um projeto de Machine Learning pode ser dividido em três etapas principais:\n",
    "\n",
    "1. **Dados (*)**: \n",
    "   - Coleta de dados relevantes para o problema.\n",
    "   - Pré-processamento: limpeza de dados, tratamento de valores faltantes, normalização ou padronização, e divisão em conjuntos de treino e teste.\n",
    "   - Feature engineering: criar novas variáveis ou transformar as existentes para melhorar o desempenho do modelo.\n",
    "     \n",
    "    **Essa etapa é a mais importante!!!**\n",
    "\n",
    "2. **Modelos**:\n",
    "   - Escolha de um algoritmo adequado: o tipo de problema (**classificação**, **regressão**, etc.) define a escolha do modelo.\n",
    "   - Treinamento: ajustar o modelo aos dados de treino para que ele aprenda padrões nos dados.\n",
    "   - Ajuste de hiperparâmetros: afinar parâmetros do modelo para melhorar seu desempenho.\n",
    "     \n",
    "\n",
    "3. **Avaliação (Eval)**:\n",
    "   - Avaliar o desempenho do modelo em dados de teste.\n",
    "   - Métricas de avaliação: acurácia, precisão, recall, F1-score, AUC-ROC (para classificação), ou erro quadrático médio (para regressão).\n",
    "   - Validação cruzada e técnicas de otimização: garantir que o modelo generalize bem e evite overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8781ad-4428-4b26-a203-4cbd414af1f4",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6dbea-2797-4daa-aa67-738cb4855f58",
   "metadata": {},
   "source": [
    "### Dataset Iris\n",
    "\n",
    "Um dataset comum para **classificação** é o Iris Dataset, onde o objetivo é classificar espécies de flores com base em medidas de comprimento e largura de sépalas e pétalas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991dacf1-44d8-40eb-8fda-c6c055b25fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importando bibliotecas\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Carregando o dataset Iris\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando o dataset Iris\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1cf29-329e-41f5-87e6-8531b4dfeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as primeiras linhas do dataset\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bfa5d-fb6e-40f7-ab18-356c6433f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe() # função do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93726e80-67cc-4e83-9e71-0644761c7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef7c14-328d-4f25-88bf-c734b4d52255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando um gráfico de dispersão para visualização das classes\n",
    "sns.pairplot(iris, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcc4ee-020d-4bf1-b823-99713b613764",
   "metadata": {},
   "source": [
    "### Dataset California Housing\n",
    "\n",
    "Este dataset foi derivado do Censo de 1990 da Califórnia e contém os seguintes atributos preditores:\n",
    "\n",
    "- MedInc: Renda mediana dos residentes do bairro.\n",
    "- HouseAge: Idade média das casas no bairro.\n",
    "- AveRooms: Número médio de quartos por domicílio.\n",
    "- AveBedrms: Número médio de quartos por domicílio.\n",
    "- Population: População do bairro.\n",
    "- AveOccup: Número médio de residentes por domicílio.\n",
    "- Latitude: Latitude do bairro.\n",
    "- Longitude: Longitude do bairro.\n",
    "\n",
    "A variável alvo é o valor médio das casas em milhares de dólares, representado como MedHouseVal (em milhares de dólares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca710c7-9904-43f3-b0fc-a8416bad9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregando o dataset\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "df = california_housing.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008d610-e036-4b15-bc6f-31ebc2c20775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as primeiras linhas do dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d801f-1218-4ed8-b573-b3ce4dbe1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizando a distribuição do preço médio das casas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['MedHouseVal'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribuição dos preços das casas')\n",
    "plt.xlabel('MedHouseVal')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4001b-73e3-49ef-994c-da205097ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Calcular a média e o desvio padrão da coluna 'MedInc' (renda média)\n",
    "medinc = df['MedInc'].values  # Obter a coluna como array NumPy\n",
    "\n",
    "mean_medinc = np.mean(medinc)  # Média da renda média\n",
    "std_medinc = np.std(medinc)    # Desvio padrão da renda média\n",
    "\n",
    "print(f\"Média da renda média: {mean_medinc}\")\n",
    "print(f\"Desvio padrão da renda média: {std_medinc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfcb63-9e27-4e7e-be30-aa3844bb21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MedInc'] + df['MedInc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41d7ac-8a09-4c1b-8df6-9d95f163cd43",
   "metadata": {},
   "source": [
    "## Bibliotecas Basicas\n",
    "\n",
    "Para trabalhar com dados em Python, utilizamos as seguintes bibliotecas:\n",
    "\n",
    "1. **pandas**:\n",
    "   - **Descrição**: Pandas é uma biblioteca poderosa para análise e manipulação de dados, oferecendo estruturas de dados como DataFrames, que facilitam o processamento e a análise de grandes volumes de dados.\n",
    "   - **Uso**: Utilizada para carregar e exibir datasets tabulares, como no caso do Iris Dataset e do California Housing Dataset.\n",
    "\n",
    "\n",
    "2. **matplotlib**:\n",
    "   - **Descrição**: Matplotlib é uma biblioteca popular para criar visualizações 2D, como gráficos de linhas, dispersão, histogramas, entre outros. É uma ferramenta fundamental para visualizações personalizadas.\n",
    "   - **Uso**: Utilizada para criar gráficos como histogramas para explorar a distribuição de variáveis (por exemplo, no California Housing Dataset).\n",
    "\n",
    "\n",
    "3. **seaborn**:\n",
    "   - **Descrição**: Seaborn é uma biblioteca baseada no matplotlib que facilita a criação de gráficos estatísticos bonitos e informativos. Oferece uma interface simples para visualizações de dados.\n",
    "   - **Uso**: Utilizada para visualizar dados com gráficos, como o `pairplot` para explorar relações entre variáveis no Iris Dataset.\n",
    "\n",
    "\n",
    "4. **NumPy**\n",
    "- **Descrição**: NumPy (Numerical Python) é uma biblioteca essencial para computação científica em Python, fornecendo suporte para arrays multidimensionais, além de funções matemáticas, lógicas e transformações. É amplamente utilizada para manipulação eficiente de grandes conjuntos de dados numéricos e cálculos complexos, como álgebra linear, transformadas de Fourier e geração de números aleatórios.\n",
    "\n",
    "- **Uso**: Utilizada para realizar operações matriciais, cálculos vetorizados e manipulação de dados numéricos em aplicações de aprendizado de máquina, como no pré-processamento de dados ou cálculos de otimização.\n",
    "\n",
    "5. **scikit-learn**:\n",
    "   - **Descrição**: Falaremos sobre ela no futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38ba57-1df4-4154-9ca0-dbe34a2e8667",
   "metadata": {},
   "source": [
    "## Problemas Clássicos no Processamento de Dados e Soluções com Python\n",
    "\n",
    "Em projetos de Machine Learning, o processamento de dados é uma etapa crítica. Abaixo estão alguns problemas comuns encontrados durante essa fase e como resolvê-los utilizando ferramentas do Python.\n",
    "\n",
    "1. **Dados Faltantes**:\n",
    "   - **Descrição**: Dados ausentes (missing values) podem comprometer a análise e a precisão dos modelos.\n",
    "   - **Solução**: Podemos substituir os valores ausentes com `fillna()` ou remover linhas/colunas incompletas com `dropna()` do **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671d55e-1121-4c31-99c0-1432454595d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"novo\"] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d7643-69dc-4c6e-b467-924a39d00ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)  # Substitui valores faltantes pela média da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f25f0-56fc-4fbe-b4ac-9774f34401bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()  # Remove linhas com valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2856a-fc28-4350-8c9d-15bd5c40d407",
   "metadata": {},
   "source": [
    "2. **Dados Duplicados**:\n",
    "   - **Descrição**: Dados duplicados podem distorcer as conclusões e enviesar os resultados.\n",
    "   - **Solução**: Usar o método `drop_duplicates()` do **pandas** para remover duplicatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac80c50-e53d-4769-8caf-edd4cd187d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()  # Remove duplicatas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0719b-2ff1-4341-88db-53de53acff7b",
   "metadata": {},
   "source": [
    "3. **Outliers**:\n",
    "   - **Descrição**: Outliers são valores extremos que não seguem o padrão do resto dos dados e podem impactar negativamente a performance do modelo.\n",
    "   - **Solução**: Detectar outliers com o método do intervalo interquartil (IQR) e removê-los ou limitar os valores com `clip()` do **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ea0f3-b7c4-42ad-8e6c-e7db35d5c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.05)\n",
    "Q3 = df.quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "df_outliers_removed = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e5b82-efae-41db-8c52-097bd93fa825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers_removed.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd2abf-3b55-44cf-8ed5-458c80d157e5",
   "metadata": {},
   "source": [
    "4. **Escalonamento de Variáveis**:\n",
    "   - **Descrição**: Variáveis com diferentes escalas podem prejudicar algoritmos que dependem da distância entre valores, como KNN e Regressão Linear.\n",
    "   - **Solução**: Normalizar ou padronizar as variáveis usando `MinMaxScaler()` ou `StandardScaler()` da biblioteca **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a4736-c5b5-43c8-bd26-f2661213629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()  # Normalização entre 0 e 1\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "scaler_standard = StandardScaler()  # Padronização (média 0, desvio padrão 1)\n",
    "df_standardized = scaler_standard.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a2209-a31a-4aa3-b680-8fe9b0e47b03",
   "metadata": {},
   "source": [
    "5. **Colinearidade**:\n",
    "   - **Descrição**: Variáveis altamente correlacionadas podem fornecer informações redundantes e atrapalhar o desempenho de alguns modelos.\n",
    "   - **Solução**: Calcular a matriz de correlação com o **pandas** e remover ou transformar variáveis colineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7d159-eb39-448a-858f-cfff37bab772",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.drop(columns=[\"Longitude\", \"Latitude\"]).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)  # Exibe a matriz de correlação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009360b-cd35-4fda-a66c-34b7e4aa1065",
   "metadata": {},
   "source": [
    "6. **Dados Desbalanceados**:\n",
    "   - **Descrição**: Em problemas de classificação, classes desbalanceadas podem levar o modelo a favorecer a classe majoritária, ignorando a minoritária.\n",
    "   - **Solução**: Usar métricas de avaliação como **F1-score**, **recall**, **precision** e **AUC-ROC**, que são menos sensíveis ao desbalanceamento do que a simples acurácia. (falaremos mais sobre isso no futuro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8cbd6-59e8-45c0-afc7-8b18aa7922a6",
   "metadata": {},
   "source": [
    "7. **Formatação Inconsistente**:\n",
    "   - **Descrição**: Dados vindos de diferentes fontes podem ter formatação inconsistente, como diferentes formatos de datas ou capitalização variada.\n",
    "   - **Solução**: Padronizar formatação com métodos como `pd.to_datetime()` para datas e `str.lower()` para strings no **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776f2bf-c7cc-410d-81a6-abe306c3a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'bob', 'Carlos'],\n",
    "    'Data_Venda': ['2023/10/01', '01-10-2023', '10/01/2023']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcf687-2006-4e42-b082-f27c2d536f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_str):\n",
    "    for fmt in ('%Y/%m/%d', '%d-%m-%Y', '%m/%d/%Y', '%Y.%m.%d'):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT  # Retorna NaT caso nenhum formato funcione\n",
    "\n",
    "# Padronizar a capitalização dos nomes (tudo minúsculo)\n",
    "df['Nome'] = df['Nome'].str.lower()\n",
    "\n",
    "# Aplicar a função para padronizar as datas\n",
    "df['Data_Venda'] = df['Data_Venda'].apply(parse_date)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace184e8-15d3-4629-84e8-ff06473a53a7",
   "metadata": {},
   "source": [
    "9. **Transformação de Dados Categóricos**:\n",
    "   - **Descrição**: Variáveis categóricas não podem ser diretamente utilizadas por muitos algoritmos de aprendizado de máquina.\n",
    "   - **Solução**: Converter variáveis categóricas em variáveis numéricas usando **pandas** `get_dummies()` ou `LabelEncoder()` da **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab0155-56ab-40d1-956f-c1bfe2769eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de DataFrame simples com uma variável categórica\n",
    "df = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Carlos', 'Diana'],\n",
    "    'Cor_Favorita': ['Vermelho', 'Azul', 'Verde', 'Azul']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b366e85-db3d-4181-8f64-84a8e8e8dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a variável categórica 'Cor_Favorita' em variáveis dummy (one-hot encoding)\n",
    "df_dummies = pd.get_dummies(df, columns=['Cor_Favorita'])\n",
    "\n",
    "print(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5311a-ced5-41d4-930c-7a21b62f5e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
